{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve7_Y_NsI2A7",
        "outputId": "c29592b7-29f0-4549-f24c-c5bf0b430446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset: (162980, 2)\n",
            "\n",
            "Columns: ['clean_text', 'category']\n",
            "\n",
            "Null values:\n",
            " clean_text    4\n",
            "category      7\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            " clean_text     object\n",
            "category      float64\n",
            "dtype: object\n",
            "\n",
            "Sample rows:\n",
            "                                          clean_text  category\n",
            "0  when modi promised “minimum government maximum...      -1.0\n",
            "1  talk all the nonsense and continue all the dra...       0.0\n",
            "2  what did just say vote for modi  welcome bjp t...       1.0\n",
            "3  asking his supporters prefix chowkidar their n...       1.0\n",
            "4  answer who among these the most powerful world...       1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/Twitter_Data.csv')\n",
        "\n",
        "print(\"Shape of dataset:\", df.shape)\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "print(\"\\nNull values:\\n\", df.isnull().sum())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "\n",
        "print(\"\\nSample rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['clean_text', 'category'])\n",
        "df['category'] = df['category'].astype(int)\n",
        "df['category'] = df['category'].map({0: \"Neutral\", -1: \"Negative\", 1: \"Positive\"})\n"
      ],
      "metadata": {
        "id": "fEvZazDUjkzD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "print(\"\\nMissing values after cleaning:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwDR5QFojovE",
        "outputId": "37e3fa0b-9599-46b2-de63-00035f09ef16"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before cleaning:\n",
            " clean_text    0\n",
            "category      0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after cleaning:\n",
            " clean_text    0\n",
            "category      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    words = [word for word in text.split() if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "df['clean_text'] = df['clean_text'].astype(str).apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4_lWsD0kHbc",
        "outputId": "c4b9b3db-85cf-4553-c1d6-5312da4cd2cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df['clean_text'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "R_yLCs4mkOiI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_text']\n",
        "y = df['category']"
      ],
      "metadata": {
        "id": "61sgqe8Zkeu4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "XuJWsTTgkhCv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X_sequences = tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "DPyKCu_ak23t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(x) for x in X_sequences])\n",
        "X_padded = pad_sequences(X_sequences, maxlen=max_length, padding='pre')"
      ],
      "metadata": {
        "id": "ABKi40NMk8Mr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)"
      ],
      "metadata": {
        "id": "besjQ2U7lAq-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MBrp8jd_lFQo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "wWR1fvSSlLkc",
        "outputId": "82a7c41c-e591-4f37-bc83-47f76a2bc800"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIamTkQnlbxf",
        "outputId": "09df1e6b-403e-439a-a85c-2453ccaf87a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 95ms/step - accuracy: 0.7690 - loss: 0.5776 - val_accuracy: 0.9058 - val_loss: 0.3166\n",
            "Epoch 2/5\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 98ms/step - accuracy: 0.9083 - loss: 0.3060 - val_accuracy: 0.9057 - val_loss: 0.3104\n",
            "Epoch 3/5\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 94ms/step - accuracy: 0.9110 - loss: 0.2856 - val_accuracy: 0.9084 - val_loss: 0.3035\n",
            "Epoch 4/5\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 98ms/step - accuracy: 0.9171 - loss: 0.2605 - val_accuracy: 0.9096 - val_loss: 0.3052\n",
            "Epoch 5/5\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 97ms/step - accuracy: 0.9196 - loss: 0.2438 - val_accuracy: 0.9046 - val_loss: 0.3185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred_normalized = (y_pred == y_pred.max(axis=1, keepdims=True)).astype(int)\n",
        "\n",
        "print(\"Sample prediction probabilities:\\n\", y_pred[:5])\n",
        "print(\"\\nNormalized predictions:\\n\", y_pred_normalized[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyHrE4oLptzE",
        "outputId": "b94cbdd1-8429-49b5-a38c-882283fc94f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1019/1019\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 22ms/step\n",
            "Sample prediction probabilities:\n",
            " [[2.2945207e-02 8.1843585e-01 1.5861893e-01]\n",
            " [3.2476105e-02 4.7943604e-04 9.6704447e-01]\n",
            " [8.4607112e-01 4.8940810e-03 1.4903466e-01]\n",
            " [8.1387305e-01 2.8125212e-02 1.5800172e-01]\n",
            " [2.9817346e-01 4.6708623e-01 2.3474029e-01]]\n",
            "\n",
            "Normalized predictions:\n",
            " [[0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "y_pred_labels = np.argmax(y_pred_normalized, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_labels, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxecAbZApwSu",
        "outputId": "c4996704-3fc2-459f-e170-d2732432e797"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9046450266920292\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.87      0.84      0.85      7152\n",
            "     Neutral       0.89      0.96      0.92     11067\n",
            "    Positive       0.93      0.90      0.91     14375\n",
            "\n",
            "    accuracy                           0.90     32594\n",
            "   macro avg       0.90      0.90      0.90     32594\n",
            "weighted avg       0.91      0.90      0.90     32594\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 5972   485   695]\n",
            " [  204 10591   272]\n",
            " [  659   793 12923]]\n"
          ]
        }
      ]
    }
  ]
}
